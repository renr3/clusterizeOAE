{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58161d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Processing: Barão de Grajaú\n",
      "======================================================================\n",
      "Total points: 6\n",
      "Creating 1 cluster(s) (max 10 points each)\n",
      "\n",
      "======================================================================\n",
      "Processing: Caxias\n",
      "======================================================================\n",
      "Total points: 10\n",
      "Creating 1 cluster(s) (max 10 points each)\n",
      "\n",
      "======================================================================\n",
      "Processing: Imperatriz\n",
      "======================================================================\n",
      "Total points: 3\n",
      "Creating 1 cluster(s) (max 10 points each)\n",
      "\n",
      "======================================================================\n",
      "Processing: Pedrinhas\n",
      "======================================================================\n",
      "Total points: 26\n",
      "Creating 3 cluster(s) (max 10 points each)\n",
      "Initial geographic clustering...\n",
      "\n",
      "======================================================================\n",
      "Processing: Presidente Dutra\n",
      "======================================================================\n",
      "Total points: 2\n",
      "Creating 1 cluster(s) (max 10 points each)\n",
      "\n",
      "======================================================================\n",
      "Processing: Santa Inês\n",
      "======================================================================\n",
      "Total points: 17\n",
      "Creating 2 cluster(s) (max 10 points each)\n",
      "Initial geographic clustering...\n",
      "     CodPro  Código (SGE)                               Identificação da OAE  \\\n",
      "0   OAE5022      150026.0                            Ponte sobre o Rio Cocal   \n",
      "1   OAE5026      150030.0                 Ponte sobre o Riacho Amola Machado   \n",
      "2   OAE5028      150032.0                  Ponte sobre o Riacho Cachoeira II   \n",
      "3   OAE5031      150035.0  Ponte sobre o Rio Sucuruju / Ponte sobre o Ria...   \n",
      "4   OAE5052      150056.0                    Ponte sobre o Riacho dos Porcos   \n",
      "..      ...           ...                                                ...   \n",
      "59  OAE5126      150130.0                          Ponte sobre o Rio Pindaré   \n",
      "60  OAE5189      150193.0                 Ponte sobre o Braço do Rio Pindaré   \n",
      "61  OAE5190      150194.0                          Ponte sobre o Rio Turiaçu   \n",
      "62  OAE5193      150197.0                    Ponte sobre o Igarapé da Cigana   \n",
      "63  OAE5217      150221.0                       Ponte sobre o Riacho Bombasa   \n",
      "\n",
      "   Rodovia  UF        Município      km  Latitude  Longitude  Nota PROARTE  \\\n",
      "0   BR-230  MA           BALSAS  394.63 -7.446883 -46.009333           1.0   \n",
      "1   BR-230  MA  BARAO DE GRAJAU   10.63 -6.727083 -43.097517           NaN   \n",
      "2   BR-230  MA  BARAO DE GRAJAU    7.05 -6.739133 -43.067550           NaN   \n",
      "3   BR-230  MA  BARAO DE GRAJAU    8.74 -6.733500 -43.081683           NaN   \n",
      "4   BR-230  MA  BARAO DE GRAJAU    4.22 -6.748267 -43.043733           NaN   \n",
      "..     ...  ..              ...     ...       ...        ...           ...   \n",
      "59  BR-316  MA              NaN  251.11 -3.658600 -45.468650           1.0   \n",
      "60  BR-316  MA              NaN  253.11 -3.658383 -45.451633           1.0   \n",
      "61  BR-316  MA              NaN  160.47 -2.943233 -45.667667           1.0   \n",
      "62  BR-316  MA              NaN  287.34 -3.798350 -45.205017           1.0   \n",
      "63  BR-222  MA              NaN  262.74 -3.573650 -44.683250           1.0   \n",
      "\n",
      "   Nota SGE  Nota Inspeção Nota Final  \\\n",
      "0         4            1.0          1   \n",
      "1         2            NaN          2   \n",
      "2         2            NaN          2   \n",
      "3         2            NaN          2   \n",
      "4         2            NaN          2   \n",
      "..      ...            ...        ...   \n",
      "59        3            1.0          1   \n",
      "60        3            1.0          1   \n",
      "61        2            1.0          1   \n",
      "62        4            1.0          1   \n",
      "63        1            1.0          1   \n",
      "\n",
      "                                  PARECER SUPERVISORA PARECER PROARTE  \\\n",
      "0   Elementos com concreto desagregado e exposição...       Aceitável   \n",
      "1                                                 NaN             NaN   \n",
      "2                                                 NaN             NaN   \n",
      "3                                                 NaN             NaN   \n",
      "4                                                 NaN             NaN   \n",
      "..                                                ...             ...   \n",
      "59                                                NaN   Não aceitável   \n",
      "60  A ponte não tem mais cortina de contenção em u...    Questionável   \n",
      "61  A ponte apresenta situação crítica. Sua fundaç...       Aceitável   \n",
      "62  A ponte apresenta afundamentgo no pavimento po...   Não aceitável   \n",
      "63  Um problema crítico identificado é a erosão na...       Aceitável   \n",
      "\n",
      "   DIRECIONAMENTO PROARTE      MAN_Status_Detalhado       MAN_Status_Resumido  \\\n",
      "0                Urgência  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "1                     NaN  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "2                     NaN  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "3                     NaN  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "4                     NaN  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "..                    ...                       ...                       ...   \n",
      "59               Urgência  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "60               Urgência  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "61               Urgência  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "62               Urgência  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "63           Reabilitação  07 - PTO NO SEI + ANEXOS  03 - MANUTENÇÃO PREVISTA   \n",
      "\n",
      "                  REAB_Status_Detalhado        REAB_Status_Resumido  \\\n",
      "0                                   NaN                         NaN   \n",
      "1                      04 - ANTEPROJETO  06 - REABILITAÇÃO PREVISTA   \n",
      "2                      04 - ANTEPROJETO  06 - REABILITAÇÃO PREVISTA   \n",
      "3                      04 - ANTEPROJETO  06 - REABILITAÇÃO PREVISTA   \n",
      "4                      04 - ANTEPROJETO  06 - REABILITAÇÃO PREVISTA   \n",
      "..                                  ...                         ...   \n",
      "59                          17 - OUTROS                 13 - OUTROS   \n",
      "60  01 - OAE INDICADA PARA REABILITAÇÃO            02 - SELECIONADA   \n",
      "61  01 - OAE INDICADA PARA REABILITAÇÃO            02 - SELECIONADA   \n",
      "62  01 - OAE INDICADA PARA REABILITAÇÃO            02 - SELECIONADA   \n",
      "63                   13 - REDIRECIONADA          09 - REDIRECIONADA   \n",
      "\n",
      "                  INTERVENÇÃO RELATÓRIO SUPERVISORA     DATA DA INSPEÇÃO  \\\n",
      "0                  MANUTENÇÃO              20184435  2024-12-27 00:00:00   \n",
      "1   MANUTENÇÃO | REABILITAÇÃO                   NaN                  NaN   \n",
      "2   MANUTENÇÃO | REABILITAÇÃO                   NaN                  NaN   \n",
      "3   MANUTENÇÃO | REABILITAÇÃO                   NaN                  NaN   \n",
      "4   MANUTENÇÃO | REABILITAÇÃO                   NaN                  NaN   \n",
      "..                        ...                   ...                  ...   \n",
      "59  MANUTENÇÃO | REABILITAÇÃO              20466935  2025-02-04 00:00:00   \n",
      "60  MANUTENÇÃO | REABILITAÇÃO              20497135  2025-02-04 00:00:00   \n",
      "61  MANUTENÇÃO | REABILITAÇÃO              20497135  2025-01-21 00:00:00   \n",
      "62  MANUTENÇÃO | REABILITAÇÃO              20497135  2025-02-04 00:00:00   \n",
      "63  MANUTENÇÃO | REABILITAÇÃO              20466935  2024-11-26 00:00:00   \n",
      "\n",
      "   SEI DO PARECER merge_key   Custo final    Unidade Local  NOTA CONSOLIDADA  \\\n",
      "0             NaN    150026  5.896908e+06  Barão de Grajaú                 1   \n",
      "1             NaN    150030  7.779521e+05  Barão de Grajaú                 2   \n",
      "2             NaN    150032  1.193945e+06  Barão de Grajaú                 2   \n",
      "3             NaN    150035  1.452780e+06  Barão de Grajaú                 2   \n",
      "4             NaN    150056  9.768641e+05  Barão de Grajaú                 2   \n",
      "..            ...       ...           ...              ...               ...   \n",
      "59            NaN    150130  2.188993e+07       Santa Inês                 1   \n",
      "60            NaN    150193  2.672398e+06       Santa Inês                 1   \n",
      "61            NaN    150194  1.314679e+07       Santa Inês                 1   \n",
      "62            NaN    150197  3.601592e+06       Santa Inês                 1   \n",
      "63            NaN    150221  6.648776e+05       Santa Inês                 1   \n",
      "\n",
      "         LAT       LONG  cluster       cluster_label  \n",
      "0  -7.446883 -46.009333        0  Barão de Grajaú-C0  \n",
      "1  -6.727083 -43.097517        0  Barão de Grajaú-C0  \n",
      "2  -6.739133 -43.067550        0  Barão de Grajaú-C0  \n",
      "3  -6.733500 -43.081683        0  Barão de Grajaú-C0  \n",
      "4  -6.748267 -43.043733        0  Barão de Grajaú-C0  \n",
      "..       ...        ...      ...                 ...  \n",
      "59 -3.658600 -45.468650        8       Santa Inês-C8  \n",
      "60 -3.658383 -45.451633        8       Santa Inês-C8  \n",
      "61 -2.943233 -45.667667        8       Santa Inês-C8  \n",
      "62 -3.798350 -45.205017        8       Santa Inês-C8  \n",
      "63 -3.573650 -44.683250        7       Santa Inês-C7  \n",
      "\n",
      "[64 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Progress bar\n",
    "# progress_bar = st.progress(0)\n",
    "path=\"Z:\\\\09-LOTES REABILITAÇÃO\"\n",
    "file1=f\"{path}\\\\MAPEAMENTO_INSPEÇÕES_20201021.xlsx\"\n",
    "df1 = pd.read_excel(file1, header=1, usecols=\"B:Y\", decimal=\",\")\n",
    "# progress_bar.progress(10)\n",
    "file2=f\"{path}\\\\Estudo Paramétrico_20251021.xlsx\"\n",
    "df2 = pd.read_excel(file2, sheet_name=\"Simulação\", header=2, usecols=\"B:AS\", decimal=\",\")\n",
    "# progress_bar.progress(20)\n",
    "file3=f\"{path}\\\\CONTROLE GERAL PROARTE.xlsx\"\n",
    "df3 = pd.read_excel(file3, sheet_name=\"CONTROLE GERAL PROARTE\", header=0, decimal=\",\")\n",
    "# progress_bar.progress(30)\n",
    "df3 = df3.drop_duplicates(subset=\"CodPro\", keep=\"first\")\n",
    "# progress_bar.progress(40)\n",
    "\n",
    "# MERGING DATAFRAMES WITH CLEANING\n",
    "def clean_numerical_code(series):\n",
    "    \"\"\"Convert any format to clean integer string\"\"\"\n",
    "    return (\n",
    "        series\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace('.0', '', regex=False)\n",
    "        .str.replace(',', '', regex=False)\n",
    "    )\n",
    "\n",
    "# Cleaning merge keys\n",
    "df1['merge_key'] = clean_numerical_code(df1['Código (SGE)'])\n",
    "df1['CodPro'] = clean_numerical_code(df1['CodPro'])\n",
    "df2['merge_key'] = clean_numerical_code(df2['SGE_AJUSTE'])\n",
    "df3['CodPro'] = clean_numerical_code(df3['CodPro'])\n",
    "\n",
    "# progress_bar.progress(50)\n",
    "\n",
    "# Merge df1 with df2\n",
    "df_merged = df1.merge(\n",
    "    df2[['merge_key', 'Custo final']],\n",
    "    on='merge_key',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge with df3 to get Nota Final\n",
    "df_merged = df_merged.merge(\n",
    "    df3[['CodPro', 'Unidade Local']],\n",
    "    on='CodPro',\n",
    "    how='left',\n",
    "    suffixes=('', '_df3')\n",
    ")\n",
    "# progress_bar.progress(60)\n",
    "\n",
    "def process_nota_final(value):\n",
    "    if isinstance(value, str):\n",
    "        if value.strip().upper() == \"S/N\":\n",
    "            return -99\n",
    "        value = value.replace(\",\", \".\")\n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except:\n",
    "        return -99  # fallback in case of unexpected formats\n",
    "    \n",
    "df_merged['NOTA CONSOLIDADA'] = df_merged['Nota Final'].apply(process_nota_final)\n",
    "\n",
    "\n",
    "# MAKE INITIAL CLUSTER\n",
    "\n",
    "# Initialize cache and API counter\n",
    "distance_cache = {}\n",
    "api_call_count = 0\n",
    "\n",
    "def get_road_distance(lat1, lon1, lat2, lon2, show_progress=True):\n",
    "    \"\"\"Get road travel distance between two points using OSRM\"\"\"\n",
    "    global distance_cache, api_call_count\n",
    "\n",
    "    if lat1 == lat2 and lon1 == lon2:\n",
    "        return 0.0\n",
    "\n",
    "    key = f\"{lat1:.6f},{lon1:.6f}|{lat2:.6f},{lon2:.6f}\"\n",
    "    rev_key = f\"{lat2:.6f},{lon2:.6f}|{lat1:.6f},{lon1:.6f}\"\n",
    "\n",
    "    if key in distance_cache:\n",
    "        return distance_cache[key]\n",
    "    if rev_key in distance_cache:\n",
    "        return distance_cache[rev_key]\n",
    "\n",
    "    url = (\n",
    "        f\"http://router.project-osrm.org/route/v1/driving/\"\n",
    "        f\"{lon1},{lat1};{lon2},{lat2}\"\n",
    "        f\"?overview=false\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        api_start_time = time.time()\n",
    "        response = requests.get(url, timeout=10)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"routes\" in data and len(data[\"routes\"]) > 0:\n",
    "            distance_meters = data[\"routes\"][0][\"distance\"]\n",
    "            distance_km = distance_meters / 1000.0\n",
    "            distance_cache[key] = distance_km\n",
    "            api_call_count += 1\n",
    "\n",
    "            if show_progress:\n",
    "                elapsed_ms = (time.time() - api_start_time) * 1000\n",
    "                print(f\"    [API Call #{api_call_count}] Distance: {distance_km:.2f} km | Time: {elapsed_ms:.0f}ms\")\n",
    "\n",
    "            return distance_km\n",
    "        else:\n",
    "            if show_progress:\n",
    "                print(f\"    Warning: OSRM no route found\")\n",
    "            return float('inf')\n",
    "    except Exception as e:\n",
    "        if show_progress:\n",
    "            print(f\"    Error fetching OSRM route: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate straight-line distance between two points in km\"\"\"\n",
    "    if lat1 == lat2 and lon1 == lon2:\n",
    "        return 0.0\n",
    "\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "# CONFIGURATION\n",
    "analysed_state = \"MA\"\n",
    "max_cluster_size = 10\n",
    "\n",
    "# Filter data\n",
    "notaMinima = pd.to_numeric(1, errors='coerce')\n",
    "notaMaxima = pd.to_numeric(2, errors='coerce')\n",
    "df_filtered = df_merged[\n",
    "    (df_merged['UF'] == analysed_state) &\n",
    "    (df_merged['NOTA CONSOLIDADA'] >= notaMinima) &\n",
    "    (df_merged['NOTA CONSOLIDADA'] <= notaMaxima) &\n",
    "    (pd.notna(df_merged['Latitude'])) &\n",
    "    (pd.notna(df_merged['Longitude'])) &\n",
    "    (pd.notna(df_merged['Unidade Local'])) &\n",
    "    (pd.notna(df_merged['Custo final']))\n",
    "].copy()\n",
    "\n",
    "df_filtered['LAT'] = df_filtered['Latitude']\n",
    "df_filtered['LONG'] = df_filtered['Longitude']\n",
    "# progress_bar.progress(70)\n",
    "\n",
    "def calculate_cluster_metrics(df, cluster_col='cluster', use_road_distance=False):\n",
    "    \"\"\"Calculate metrics for each cluster\"\"\"\n",
    "    metrics = {}\n",
    "    for cluster_id in df[cluster_col].unique():\n",
    "        cluster_data = df[df[cluster_col] == cluster_id]\n",
    "        coords = cluster_data[['LAT', 'LONG']].values\n",
    "\n",
    "        max_dist = 0\n",
    "        if len(coords) > 1:\n",
    "            for i in range(len(coords)):\n",
    "                for j in range(i+1, len(coords)):\n",
    "                    if use_road_distance:\n",
    "                        dist = get_road_distance(coords[i][0], coords[i][1],\n",
    "                                                coords[j][0], coords[j][1],\n",
    "                                                show_progress=False)\n",
    "                    else:\n",
    "                        dist = haversine_distance(coords[i][0], coords[i][1],\n",
    "                                                coords[j][0], coords[j][1])\n",
    "                    max_dist = max(max_dist, dist)\n",
    "\n",
    "        avg_dist = 0\n",
    "        if len(coords) > 1:\n",
    "            distances = []\n",
    "            for i in range(len(coords)):\n",
    "                for j in range(i+1, len(coords)):\n",
    "                    if use_road_distance:\n",
    "                        dist = get_road_distance(coords[i][0], coords[i][1],\n",
    "                                                coords[j][0], coords[j][1],\n",
    "                                                show_progress=False)\n",
    "                    else:\n",
    "                        dist = haversine_distance(coords[i][0], coords[i][1],\n",
    "                                                coords[j][0], coords[j][1])\n",
    "                    distances.append(dist)\n",
    "            avg_dist = np.mean(distances) if distances else 0\n",
    "\n",
    "        metrics[cluster_id] = {\n",
    "            'n_points': len(cluster_data),\n",
    "            'cost': cluster_data['Custo final'].sum(),\n",
    "            'max_distance': max_dist,\n",
    "            'avg_distance': avg_dist\n",
    "        }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def cluster_unidade_local(df_ul, unidade_name):\n",
    "    \"\"\"Cluster points within a single Unidade Local\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing: {unidade_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total points: {len(df_ul)}\")\n",
    "\n",
    "    if len(df_ul) == 0:\n",
    "        return df_ul\n",
    "\n",
    "    n_clusters = max(1, int(np.ceil(len(df_ul) / max_cluster_size)))\n",
    "    print(f\"Creating {n_clusters} cluster(s) (max {max_cluster_size} points each)\")\n",
    "\n",
    "    coords = df_ul[['LAT', 'LONG']].values\n",
    "\n",
    "    if n_clusters == 1:\n",
    "        df_ul['cluster'] = 0\n",
    "        return df_ul\n",
    "\n",
    "    print(\"Initial geographic clustering...\")\n",
    "    # Normalize cost to similar scale as coordinates\n",
    "    cost_normalized = df_ul['Custo final'] / df_ul['Custo final'].max()\n",
    "\n",
    "    # Create feature matrix with lat, lon, AND normalized cost\n",
    "    features = np.column_stack([\n",
    "        coords,  # lat, lon\n",
    "        cost_normalized * 1  # weighted cost\n",
    "    ])\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(features)\n",
    "\n",
    "    df_ul['cluster'] = clusters  # Use the cost-aware result!\n",
    "\n",
    "    return df_ul\n",
    "\n",
    "# # Process each Unidade Local\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"CLUSTERING ANALYSIS BY UNIDADE LOCAL\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "unidades_locais = df_filtered['Unidade Local'].unique()\n",
    "# print(f\"\\nFound {len(unidades_locais)} unique Unidade Local(s)\")\n",
    "\n",
    "global_cluster_id = 0\n",
    "result_dfs = []\n",
    "\n",
    "for unidade in sorted(unidades_locais):\n",
    "    df_ul = df_filtered[df_filtered['Unidade Local'] == unidade].copy()\n",
    "    df_ul = cluster_unidade_local(df_ul, unidade)\n",
    "    df_ul['cluster'] = df_ul['cluster'] + global_cluster_id\n",
    "    global_cluster_id = df_ul['cluster'].max() + 1\n",
    "    df_ul['cluster_label'] = df_ul.apply(\n",
    "        lambda row: f\"{row['Unidade Local']}-C{row['cluster']}\", axis=1\n",
    "    )\n",
    "    result_dfs.append(df_ul)\n",
    "\n",
    "df_final = pd.concat(result_dfs, ignore_index=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df_final)\n",
    "pd.reset_option('display.max_rows')\n",
    "# progress_bar.progress(80)\n",
    "\n",
    "# Calculate centroids for each cluster\n",
    "cluster_centroids = []\n",
    "for cluster_id in sorted(df_final['cluster'].unique()):\n",
    "    cluster_data = df_final[df_final['cluster'] == cluster_id]\n",
    "    centroid_lat = cluster_data['LAT'].mean()\n",
    "    centroid_lon = cluster_data['LONG'].mean()\n",
    "    cluster_label = cluster_data['cluster_label'].iloc[0]\n",
    "\n",
    "    cluster_centroids.append({\n",
    "        'cluster': int(cluster_id),\n",
    "        'lat': float(centroid_lat),\n",
    "        'lon': float(centroid_lon),\n",
    "        'label': str(cluster_label),\n",
    "        'n_points': len(cluster_data),\n",
    "        'total_cost': float(cluster_data['Custo final'].sum())\n",
    "    })\n",
    "# progress_bar.progress(90)\n",
    "\n",
    "# Save Excel output compatible with HTML tool\n",
    "excel_filename = f'{analysed_state.lower()}_clusters_output.xlsx'\n",
    "# print(f\"\\n{'='*70}\")\n",
    "# print(\"GENERATING EXCEL OUTPUT FOR HTML TOOL\")\n",
    "# print(f\"{'='*70}\")\n",
    "\n",
    "# Prepare \"All Points\" sheet with exact column names expected by HTML\n",
    "df_all_points = pd.DataFrame()\n",
    "\n",
    "# Add Point ID (using index)\n",
    "df_all_points['Point ID'] = range(len(df_final))\n",
    "\n",
    "# Add cluster information\n",
    "df_all_points['Cluster ID'] = df_final['cluster'].astype(int)\n",
    "df_all_points['Cluster Label'] = df_final['cluster_label']\n",
    "df_all_points['Unidade Local'] = df_final['Unidade Local']\n",
    "\n",
    "# Add SGE (if exists in original data, otherwise use a default or empty)\n",
    "if 'Código (SGE)' in df_final.columns:\n",
    "    # keep missing values and convert floats (e.g. 150026.0) to pandas nullable integers\n",
    "    df_all_points['SGE'] = df_final['Código (SGE)'].where(df_final['Código (SGE)'].notna(), pd.NA).astype('Int64')\n",
    "else:\n",
    "    df_all_points['SGE'] = pd.Series([pd.NA] * len(df_final), dtype='Int64')\n",
    "\n",
    "# Add CodPro\n",
    "df_all_points['CodPro'] = df_final['CodPro'] if 'CodPro' in df_final.columns else ''\n",
    "\n",
    "# Add coordinates\n",
    "df_all_points['Latitude'] = df_final['LAT']\n",
    "df_all_points['Longitude'] = df_final['LONG']\n",
    "\n",
    "# Add nota consolidada\n",
    "df_all_points['Nota Consolidada'] = df_final['NOTA CONSOLIDADA']\n",
    "\n",
    "# Add cost\n",
    "df_all_points['Custo Final (R$)'] = df_final['Custo final']\n",
    "\n",
    "# Add additional fields (use original column names or empty if not available)\n",
    "df_all_points['Rodovia'] = df_final['Rodovia'] if 'Rodovia' in df_final.columns else ''\n",
    "df_all_points['km'] = df_final['km'] if 'km' in df_final.columns else ''\n",
    "df_all_points['Município'] = df_final['Município'] if 'Município' in df_final.columns else ''\n",
    "df_all_points['Status Geral'] = df_final['Status Geral'] if 'Status Geral' in df_final.columns else ''\n",
    "df_all_points['Status Detalhado'] = df_final['Status Detalhado'] if 'Status Detalhado' in df_final.columns else ''\n",
    "\n",
    "# Add Dataset column (default to \"Principal\" for primary dataset)\n",
    "df_all_points['Dataset'] = 'Principal'\n",
    "\n",
    "# progress_bar.progress(95)\n",
    "# Prepare \"Cluster Summary\" sheet with exact column names expected by HTML\n",
    "cluster_summary = []\n",
    "for cluster_id in sorted(df_final['cluster'].unique()):\n",
    "    cluster_data = df_final[df_final['cluster'] == cluster_id]\n",
    "    cluster_label = cluster_data['cluster_label'].iloc[0]\n",
    "    unidade_local = cluster_data['Unidade Local'].iloc[0]\n",
    "\n",
    "    cluster_summary.append({\n",
    "        'Cluster ID': int(cluster_id),\n",
    "        'Cluster Label': cluster_label,\n",
    "        'Unidade Local': unidade_local,\n",
    "        'Number of Points': len(cluster_data),\n",
    "        'Total Cost (R$)': float(cluster_data['Custo final'].sum()),\n",
    "        'Avg Cost (R$)': float(cluster_data['Custo final'].mean()),\n",
    "    })\n",
    "\n",
    "# progress_bar.progress(97)\n",
    "\n",
    "df_summary = pd.DataFrame(cluster_summary)\n",
    "\n",
    "# Create a BytesIO buffer instead of a file\n",
    "output = io.BytesIO()\n",
    "\n",
    "# Write to Excel in memory (same logic as your notebook)\n",
    "with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
    "    df_all_points.to_excel(writer, sheet_name='All Points', index=False)\n",
    "    df_summary.to_excel(writer, sheet_name='Cluster Summary', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
